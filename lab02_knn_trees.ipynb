{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2. Метод ближайших соседей и решающие деревья."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Попов Артём Сергеевич\n",
    "\n",
    "Группа: 317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все эксперименты в этой лабораторной работе предлагается проводить на данных соревнования Amazon Employee Access Challenge: https://www.kaggle.com/c/amazon-employee-access-challenge\n",
    "\n",
    "В данной задаче предлагается предсказать, будет ли одобрен запрос сотрудника на получение доступа к тому или иному ресурсу. Все признаки являются категориальными.\n",
    "\n",
    "Для удобства данные можно загрузить по ссылке: https://www.dropbox.com/s/q6fbs1vvhd5kvek/amazon.csv\n",
    "\n",
    "Сразу прочитаем данные и создадим разбиение на обучение и контроль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td> 39353</td>\n",
       "      <td> 85475</td>\n",
       "      <td> 117961</td>\n",
       "      <td> 118300</td>\n",
       "      <td> 123472</td>\n",
       "      <td> 117905</td>\n",
       "      <td> 117906</td>\n",
       "      <td> 290919</td>\n",
       "      <td> 117908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 17183</td>\n",
       "      <td>  1540</td>\n",
       "      <td> 117961</td>\n",
       "      <td> 118343</td>\n",
       "      <td> 123125</td>\n",
       "      <td> 118536</td>\n",
       "      <td> 118536</td>\n",
       "      <td> 308574</td>\n",
       "      <td> 118539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1</td>\n",
       "      <td> 36724</td>\n",
       "      <td> 14457</td>\n",
       "      <td> 118219</td>\n",
       "      <td> 118220</td>\n",
       "      <td> 117884</td>\n",
       "      <td> 117879</td>\n",
       "      <td> 267952</td>\n",
       "      <td>  19721</td>\n",
       "      <td> 117880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 1</td>\n",
       "      <td> 36135</td>\n",
       "      <td>  5396</td>\n",
       "      <td> 117961</td>\n",
       "      <td> 118343</td>\n",
       "      <td> 119993</td>\n",
       "      <td> 118321</td>\n",
       "      <td> 240983</td>\n",
       "      <td> 290919</td>\n",
       "      <td> 118322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 1</td>\n",
       "      <td> 42680</td>\n",
       "      <td>  5905</td>\n",
       "      <td> 117929</td>\n",
       "      <td> 117930</td>\n",
       "      <td> 119569</td>\n",
       "      <td> 119323</td>\n",
       "      <td> 123932</td>\n",
       "      <td>  19793</td>\n",
       "      <td> 119325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTION  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
       "0       1     39353   85475         117961         118300         123472   \n",
       "1       1     17183    1540         117961         118343         123125   \n",
       "2       1     36724   14457         118219         118220         117884   \n",
       "3       1     36135    5396         117961         118343         119993   \n",
       "4       1     42680    5905         117929         117930         119569   \n",
       "\n",
       "   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
       "0      117905            117906       290919     117908  \n",
       "1      118536            118536       308574     118539  \n",
       "2      117879            267952        19721     117880  \n",
       "3      118321            240983       290919     118322  \n",
       "4      119323            123932        19793     119325  \n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/amazon.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94210992096188473"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# доля положительных примеров\n",
    "data.ACTION.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION 2\n",
      "RESOURCE 7518\n",
      "MGR_ID 4243\n",
      "ROLE_ROLLUP_1 128\n",
      "ROLE_ROLLUP_2 177\n",
      "ROLE_DEPTNAME 449\n",
      "ROLE_TITLE 343\n",
      "ROLE_FAMILY_DESC 2358\n",
      "ROLE_FAMILY 67\n",
      "ROLE_CODE 343\n"
     ]
    }
   ],
   "source": [
    "# число значений у признаков\n",
    "for col_name in data.columns:\n",
    "    print col_name, len(data[col_name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9831, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: kNN и категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Реализуйте три функции расстояния на категориальных признаках, которые обсуждались на втором семинаре. Реализуйте самостоятельно метод k ближайших соседей, который будет уметь работать с этими функциями расстояния. Подсчитайте для каждой из них качество на тестовой выборке `X_test` при числе соседей $k = 10$. Метрика качества — AUC-ROC.\n",
    "\n",
    "Какая функция расстояния оказалась лучшей?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все метрики были реализованы так, чтобы на выходе оказывалась матрица расстояний: в ij ячейке расстояние от i-ого объекта первой матрицы до j-го объекта второй матрицы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 метрика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dis_1_matrix(X, Z):\n",
    "    X_1 = np.array(X)\n",
    "    Z_1 = np.array(Z)\n",
    "    return np.sum(X_1[:, np.newaxis] != Z_1[np.newaxis, :], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections # для defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация вспомогательных функций f, p и p2, описанных на семинаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_f_list(data):\n",
    "    f = list()\n",
    "    for j in range(0, data.shape[1]):\n",
    "        column = data.iloc[:, j]\n",
    "        f.append(dict(column.value_counts()))        \n",
    "    return f\n",
    "\n",
    "def create_p_list(f, l):\n",
    "    p1 = list()\n",
    "    for i in range(len(f)):\n",
    "        p1.append(collections.defaultdict(int))\n",
    "        for (key, value) in f[i].items():\n",
    "            p1[i][key] = value * 1.0 / l\n",
    "    return p1\n",
    "\n",
    "def create_p2_list(f, l):\n",
    "    p2 = list()\n",
    "    for i in range(len(f)):\n",
    "        p2.append(collections.defaultdict(int))\n",
    "        for (key, value) in f[i].items():\n",
    "            p2[i][key] = value * (value - 1) * 1.0 / (l * (l - 1))\n",
    "    return p2\n",
    "\n",
    "def create_log_f(f):\n",
    "    logf = list()\n",
    "    for i in range(len(f)):\n",
    "        logf.append(collections.defaultdict(int))\n",
    "        for (key, value) in f[i].items():\n",
    "            logf[i][key] = np.log(value * 1.0)\n",
    "    return logf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 метрика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dis_2_matrix(X, Z):\n",
    "    f = create_f_list(Z)\n",
    "    p = create_p_list(f, Z.shape[0])\n",
    "    p2 = create_p2_list(f, Z.shape[0])\n",
    "    l_np_arr_p2 = [np.array(item.values()) for item in p2]\n",
    "    l_np_arr = [np.array(item.values()) for item in p]\n",
    "    \n",
    "    res = np.zeros((X.shape[0], Z.shape[0]))\n",
    "    for i, x in enumerate(np.array(X)):\n",
    "        for j, z in enumerate(np.array(Z)):\n",
    "            for k in range(X.shape[1]):\n",
    "                if (x[k] == z[k]):\n",
    "                    res[i, j] += np.sum(l_np_arr_p2[k][l_np_arr[k] <= p[k].get(x[k], 0)])\n",
    "    return res + dis_1_matrix(X, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 метрика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dis_3_matrix(X, Z):\n",
    "    f = create_f_list(Z)\n",
    "    logf = create_log_f(f)\n",
    "    res = np.zeros((X.shape[0], Z.shape[0]))\n",
    "    for i, x in enumerate(np.array(X)):\n",
    "        for j, z in enumerate(np.array(Z)):\n",
    "            for k in range(X.shape[1]):\n",
    "                if (x[k] != z[k]):\n",
    "                    res[i, j] += logf[k].get(x[k], 0) * logf[k].get(z[k], 0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключение необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, реализующая метод KNN. Внутри функции происходит подсчёт матрицы расстояний с помощью соответствующей метрики. В функции реализовано нахождение наилучшего k для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_super_KNN(X_train, y_train, X_test, y_test, my_metric):\n",
    "    matr_dis = my_metric(X_test, X_train)\n",
    "    best = 0.0\n",
    "    k_best = 1\n",
    "    for k in range(1, 25):\n",
    "        ind = matr_dis.argsort(axis=1)[:,:k]\n",
    "        num_class = np.array(y_train.as_matrix()[ind])\n",
    "        ans = np.sum(num_class, axis=1) * 1.0 / k\n",
    "        roc = roc_auc_score(y_test, ans)\n",
    "        if (k == 10):\n",
    "            print('if k == 10:')\n",
    "            print(roc)\n",
    "        if (best < roc):\n",
    "            best = roc\n",
    "            k_best = k\n",
    "    print('the best k == ' + str(k_best))\n",
    "    print(best)\n",
    "    return (k_best, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нахождение точности для k=10 и нахождение наилучшего k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if k == 10:\n",
      "0.83088009598\n",
      "the best k == 11\n",
      "0.831201958708\n"
     ]
    }
   ],
   "source": [
    "roc1 = my_super_KNN(X_train, y_train, X_test, y_test, dis_1_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if k == 10:\n",
      "0.832873632128\n",
      "the best k == 7\n",
      "0.836160998935\n"
     ]
    }
   ],
   "source": [
    "roc2 = my_super_KNN(X_train, y_train, X_test, y_test, dis_2_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if k == 10:\n",
      "0.817053027738\n",
      "the best k == 11\n",
      "0.817141176073\n"
     ]
    }
   ],
   "source": [
    "roc3 = my_super_KNN(X_train, y_train, X_test, y_test, dis_3_matrix) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 (бонус). Подберите лучшее (на тестовой выборке) число соседей $k$ для каждой из функций расстояния. Какое наилучшее качество удалось достичь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Это задание уже выполнено в предыдущем пункте. Наилучшее качество при второй метрике и k=11: 0.8361"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Реализуйте счетчики (http://blogs.technet.com/b/machinelearning/archive/2015/02/17/big-learning-made-easy-with-counts.aspx), которые заменят категориальные признаки на вещественные.\n",
    "\n",
    "А именно, каждый категориальный признак нужно заменить на три: \n",
    "1. Число `counts` объектов в обучающей выборке с таким же значением признака.\n",
    "2. Число `clicks` объектов первого класса ($y = 1$) в обучающей выборке с таким же значением признака.\n",
    "3. Сглаженное отношение двух предыдущих величин: (`clicks` + 1) / (`counts` + 2).\n",
    "\n",
    "Поскольку признаки, содержащие информацию о целевой переменной, могут привести к переобучению, может оказаться полезным сделать *фолдинг*: разбить обучающую выборку на $n$ частей, и для $i$-й части считать `counts` и `clicks` по всем остальным частям. Для тестовой выборки используются счетчики, посчитанный по всей обучающей выборке. Реализуйте и такой вариант. Можно использовать $n = 3$.\n",
    "\n",
    "#### Посчитайте на тесте AUC-ROC метода $k$ ближайших соседей с евклидовой метрикой для выборки, где категориальные признаки заменены на счетчики. Сравните по AUC-ROC два варианта формирования выборки — с фолдингом и без. Не забудьте подобрать наилучшее число соседей $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция add_counts, генерирующая обучающую и тестовую выборку с новыми признаками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_counts(X_train, y_train, X_test, y_test):\n",
    "    f = create_f_list(X_train)\n",
    "    X_new_train = pd.DataFrame()\n",
    "    X_new_test = pd.DataFrame()\n",
    "    Pos_examples = X_train.iloc[np.where(y_train == 1)[0]]\n",
    "    f_pos = create_f_list(Pos_examples)\n",
    "        \n",
    "    for j in range(X_train.shape[1]):\n",
    "        name_col = str(X_train.columns.values[j])\n",
    "        X_new_train['count_' + name_col] = X_train[name_col].apply(lambda x: f[j].get(x, 0))\n",
    "        X_new_train['clicks_' + name_col] = X_train[name_col].apply(lambda x: f_pos[j].get(x, 0))\n",
    "        X_new_train['p_' + name_col] = (X_new_train['clicks_' + name_col] + 1) * 1.0 / \\\n",
    "                                       (X_new_train['count_' + name_col] + 2)\n",
    "        X_new_test['count_' + name_col] = X_test[name_col].apply(lambda x: f[j].get(x, 0))\n",
    "        X_new_test['clicks_' + name_col] = X_test[name_col].apply(lambda x: f_pos[j].get(x, 0))\n",
    "        X_new_test['p_' + name_col] = (X_new_test['clicks_' + name_col] + 1) * 1.0 / \\\n",
    "                                      (X_new_test['count_' + name_col] + 2)\n",
    "            \n",
    "    return X_new_train, X_new_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для реализации KNN с счётчиками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def KNN_with_counts(X_train, y_train, X_test, y_test, k):\n",
    "    X_new_train, X_new_test = add_counts(X_train, y_train, X_test, y_test)\n",
    "    scaler = StandardScaler()\n",
    "    X_new_train = scaler.fit_transform(X_new_train)\n",
    "    X_new_test = scaler.transform(X_new_test)\n",
    "    clf1 = KNeighborsClassifier(n_neighbors=k)\n",
    "    clf1.fit(X_new_train, y_train)\n",
    "    return (roc_auc_score(y_test, clf1.predict_proba(X_new_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нахождение наилучшего k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 0.80185575158451372)\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "k_best = 0\n",
    "for k in range(1, 25):\n",
    "    res = KNN_with_counts(X_train, y_train, X_test, y_test, k)\n",
    "    if best < res:\n",
    "        best = res\n",
    "        k_best = k\n",
    "\n",
    "print(k_best, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшая точность при k = 19:\n",
    "\n",
    "0.80185"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, реализующая кросс-валидацию для KNN с счётчиками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def K_fold_with_params(data, k):\n",
    "    X_all_train = data.iloc[:, 1:]\n",
    "    y_all_train = data.iloc[:, 0]\n",
    "    \n",
    "    pos = 0\n",
    "    nf = 4\n",
    "    \n",
    "    kf = KFold(X_all_train.shape[0], n_folds=nf)\n",
    "    \n",
    "    for (ind_train, ind_test) in kf:\n",
    "        X_train = X_all_train.iloc[ind_train]\n",
    "        X_test = X_all_train.iloc[ind_test]\n",
    "        y_train = y_all_train.iloc[ind_train]\n",
    "        y_test = y_all_train.iloc[ind_test]\n",
    "        \n",
    "        pos += KNN_with_counts(X_train, y_train, X_test, y_test, k)\n",
    "    return pos / nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нахождение наилучшего k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 0.80874517332017737)\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "k_best = 0\n",
    "for k in range(1, 20):\n",
    "    res = K_fold_with_params(data, k)\n",
    "    if best < res:\n",
    "        best = res\n",
    "        k_best = k\n",
    "\n",
    "print(k_best, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшая точность при k = 19 (как и на тестовой выборке):\n",
    "\n",
    "0.808745"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Добавьте в исходную выборку парные признаки — то есть для каждой пары $f_i$, $f_j$ исходных категориальных признаков добавьте новый категориальный признак $f_{ij}$, значение которого является конкатенацией значений $f_i$ и $f_j$. Посчитайте счетчики для этой выборки, найдите качество метода $k$ ближайших соседей с наилучшим $k$ (с фолдингом и без)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, добавляющая парные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_counts(X_train, X_test):\n",
    "    X_new_train = pd.DataFrame()\n",
    "    X_new_test = pd.DataFrame()\n",
    "    for i in range(X_train.shape[1]):\n",
    "        name_col_i = str(X_train.columns.values[i])\n",
    "        X_new_train[name_col_i] = X_train[name_col_i]\n",
    "        X_new_test[name_col_i] = X_test[name_col_i]\n",
    "        for j in range(X_train.shape[1]):\n",
    "            if (j != i):\n",
    "                name_col_j = str(X_train.columns.values[j])\n",
    "                temp1 = X_train[name_col_i].apply(lambda x: str(x))\n",
    "                temp2 = X_train[name_col_j].apply(lambda x: str(x))\n",
    "                temp3 = X_test[name_col_i].apply(lambda x: str(x))\n",
    "                temp4 = X_test[name_col_j].apply(lambda x: str(x))\n",
    "                \n",
    "                X_new_train['concat_' + str(i) + str(j)] = temp1 + temp2\n",
    "                X_new_test['concat_' + str(i) + str(j)] = temp3 + temp4\n",
    "    return X_new_train, X_new_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_new_train, X_new_test = pair_counts(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нахождение наилучшего k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 0.82933718562224279)\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "k_best = 0\n",
    "for k in range(1, 25):\n",
    "    res = KNN_with_counts(X_new_train, y_train, X_new_test, y_test, k)\n",
    "    if best < res:\n",
    "        best = res\n",
    "        k_best = k\n",
    "        \n",
    "print(k_best, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший результат среди k от 1 до 25 при k=23: 0.82933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def K_fold_with_pairs(data, k):\n",
    "    X_all_train = data.iloc[:, 1:]\n",
    "    y_all_train = data.iloc[:, 0]\n",
    "    \n",
    "    pos = 0\n",
    "    nf = 4\n",
    "    \n",
    "    kf = KFold(X_all_train.shape[0], n_folds=nf)\n",
    "    \n",
    "    for (ind_train, ind_test) in kf:\n",
    "        X_train = X_all_train.iloc[ind_train]\n",
    "        X_test = X_all_train.iloc[ind_test]\n",
    "        y_train = y_all_train.iloc[ind_train]\n",
    "        y_test = y_all_train.iloc[ind_test]\n",
    "        X_new_train, X_new_test = pair_counts(X_train, X_test)\n",
    "        pos += KNN_with_counts(X_new_train, y_train, X_new_test, y_test, k)\n",
    "    return pos / nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нахождение наилучшего k по кросс-валидации с 4 фолдами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 0.8286647308046251)\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "k_best = 0\n",
    "\n",
    "for k in range(1, 20):\n",
    "    res = K_fold_with_pairs(data, k)\n",
    "    if best < res:\n",
    "        best = res\n",
    "        k_best = k\n",
    "        \n",
    "print(k_best, res)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее качество при k=19 (проверялись значения от 1 до 19)\n",
    "\n",
    "0.826866"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: Решающие деревья и леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Возьмите из предыдущей части выборку с парными признаками, преобразованную с помощью счетчиков без фолдинга. Настройте решающее дерево, подобрав оптимальные значения параметров `max_depth` и `min_samples_leaf`. Какой наилучший AUC-ROC на контроле удалось получить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_new_train, X_new_test = pair_counts(X_train, X_test)\n",
    "X_new_train, X_new_test = add_counts(X_new_train, y_train, X_new_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=22938, n_folds=5, shuffle=True, random_state=241),\n",
       "       error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            random_state=241, splitter='best'),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'max_depth': [2, 4, 6, 8, 10, 20, 50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(X_new_train.shape[0], shuffle=True, random_state=241, n_folds=5)\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state=241),\n",
    "                   param_grid={'max_depth': [2, 4, 6, 8, 10, 20, 50], \n",
    "                              'min_samples_leaf': range(1, 20)},\n",
    "                   cv=kf,\n",
    "                   scoring='roc_auc')\n",
    "\n",
    "gs.fit(X_new_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат с обучающей выборкой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99955563868376263"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.99956, std: 0.00079, params: {'max_depth': 4, 'min_samples_leaf': 18}\n"
     ]
    }
   ],
   "source": [
    "for z in gs.grid_scores_:\n",
    "    if z.mean_validation_score == gs.best_score_:\n",
    "        print z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С теми же параметрами на тестовой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57868977608705507"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = DecisionTreeClassifier(random_state=241, max_depth=4, min_samples_leaf=18)\n",
    "ds.fit(X_new_train, y_train)\n",
    "roc_auc_score(y_test, ds.predict_proba(X_new_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем поперебирать другие параметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.99054, std: 0.00571, params: {'max_depth': 2, 'min_samples_leaf': 1},\n",
       " mean: 0.99054, std: 0.00571, params: {'max_depth': 2, 'min_samples_leaf': 2},\n",
       " mean: 0.99054, std: 0.00571, params: {'max_depth': 2, 'min_samples_leaf': 3},\n",
       " mean: 0.99054, std: 0.00571, params: {'max_depth': 2, 'min_samples_leaf': 4},\n",
       " mean: 0.99054, std: 0.00571, params: {'max_depth': 2, 'min_samples_leaf': 5},\n",
       " mean: 0.99054, std: 0.00571, params: {'max_depth': 2, 'min_samples_leaf': 6},\n",
       " mean: 0.99054, std: 0.00570, params: {'max_depth': 2, 'min_samples_leaf': 7},\n",
       " mean: 0.99054, std: 0.00570, params: {'max_depth': 2, 'min_samples_leaf': 8},\n",
       " mean: 0.99053, std: 0.00569, params: {'max_depth': 2, 'min_samples_leaf': 9},\n",
       " mean: 0.99053, std: 0.00569, params: {'max_depth': 2, 'min_samples_leaf': 10},\n",
       " mean: 0.99053, std: 0.00569, params: {'max_depth': 2, 'min_samples_leaf': 11},\n",
       " mean: 0.99053, std: 0.00569, params: {'max_depth': 2, 'min_samples_leaf': 12},\n",
       " mean: 0.99053, std: 0.00569, params: {'max_depth': 2, 'min_samples_leaf': 13},\n",
       " mean: 0.99052, std: 0.00569, params: {'max_depth': 2, 'min_samples_leaf': 14},\n",
       " mean: 0.99052, std: 0.00569, params: {'max_depth': 2, 'min_samples_leaf': 15},\n",
       " mean: 0.99052, std: 0.00569, params: {'max_depth': 2, 'min_samples_leaf': 16},\n",
       " mean: 0.99052, std: 0.00569, params: {'max_depth': 2, 'min_samples_leaf': 17},\n",
       " mean: 0.99168, std: 0.00679, params: {'max_depth': 2, 'min_samples_leaf': 18},\n",
       " mean: 0.99168, std: 0.00679, params: {'max_depth': 2, 'min_samples_leaf': 19},\n",
       " mean: 0.99601, std: 0.00693, params: {'max_depth': 4, 'min_samples_leaf': 1},\n",
       " mean: 0.99601, std: 0.00693, params: {'max_depth': 4, 'min_samples_leaf': 2},\n",
       " mean: 0.99601, std: 0.00693, params: {'max_depth': 4, 'min_samples_leaf': 3},\n",
       " mean: 0.99601, std: 0.00693, params: {'max_depth': 4, 'min_samples_leaf': 4},\n",
       " mean: 0.99954, std: 0.00079, params: {'max_depth': 4, 'min_samples_leaf': 5},\n",
       " mean: 0.99917, std: 0.00094, params: {'max_depth': 4, 'min_samples_leaf': 6},\n",
       " mean: 0.99879, std: 0.00092, params: {'max_depth': 4, 'min_samples_leaf': 7},\n",
       " mean: 0.99879, std: 0.00092, params: {'max_depth': 4, 'min_samples_leaf': 8},\n",
       " mean: 0.99955, std: 0.00079, params: {'max_depth': 4, 'min_samples_leaf': 9},\n",
       " mean: 0.99955, std: 0.00079, params: {'max_depth': 4, 'min_samples_leaf': 10},\n",
       " mean: 0.99917, std: 0.00094, params: {'max_depth': 4, 'min_samples_leaf': 11},\n",
       " mean: 0.99955, std: 0.00079, params: {'max_depth': 4, 'min_samples_leaf': 12},\n",
       " mean: 0.99955, std: 0.00079, params: {'max_depth': 4, 'min_samples_leaf': 13},\n",
       " mean: 0.99918, std: 0.00093, params: {'max_depth': 4, 'min_samples_leaf': 14},\n",
       " mean: 0.99918, std: 0.00093, params: {'max_depth': 4, 'min_samples_leaf': 15},\n",
       " mean: 0.99918, std: 0.00093, params: {'max_depth': 4, 'min_samples_leaf': 16},\n",
       " mean: 0.99955, std: 0.00079, params: {'max_depth': 4, 'min_samples_leaf': 17},\n",
       " mean: 0.99956, std: 0.00079, params: {'max_depth': 4, 'min_samples_leaf': 18},\n",
       " mean: 0.99955, std: 0.00079, params: {'max_depth': 4, 'min_samples_leaf': 19},\n",
       " mean: 0.99788, std: 0.00183, params: {'max_depth': 6, 'min_samples_leaf': 1},\n",
       " mean: 0.99788, std: 0.00180, params: {'max_depth': 6, 'min_samples_leaf': 2},\n",
       " mean: 0.99754, std: 0.00195, params: {'max_depth': 6, 'min_samples_leaf': 3},\n",
       " mean: 0.99792, std: 0.00176, params: {'max_depth': 6, 'min_samples_leaf': 4},\n",
       " mean: 0.99755, std: 0.00146, params: {'max_depth': 6, 'min_samples_leaf': 5},\n",
       " mean: 0.99757, std: 0.00149, params: {'max_depth': 6, 'min_samples_leaf': 6},\n",
       " mean: 0.99791, std: 0.00128, params: {'max_depth': 6, 'min_samples_leaf': 7},\n",
       " mean: 0.99793, std: 0.00128, params: {'max_depth': 6, 'min_samples_leaf': 8},\n",
       " mean: 0.99797, std: 0.00178, params: {'max_depth': 6, 'min_samples_leaf': 9},\n",
       " mean: 0.99870, std: 0.00158, params: {'max_depth': 6, 'min_samples_leaf': 10},\n",
       " mean: 0.99828, std: 0.00141, params: {'max_depth': 6, 'min_samples_leaf': 11},\n",
       " mean: 0.99875, std: 0.00162, params: {'max_depth': 6, 'min_samples_leaf': 12},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 6, 'min_samples_leaf': 13},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 6, 'min_samples_leaf': 14},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 6, 'min_samples_leaf': 15},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 6, 'min_samples_leaf': 16},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 6, 'min_samples_leaf': 17},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 6, 'min_samples_leaf': 18},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 6, 'min_samples_leaf': 19},\n",
       " mean: 0.99735, std: 0.00220, params: {'max_depth': 8, 'min_samples_leaf': 1},\n",
       " mean: 0.99627, std: 0.00262, params: {'max_depth': 8, 'min_samples_leaf': 2},\n",
       " mean: 0.99596, std: 0.00255, params: {'max_depth': 8, 'min_samples_leaf': 3},\n",
       " mean: 0.99631, std: 0.00262, params: {'max_depth': 8, 'min_samples_leaf': 4},\n",
       " mean: 0.99751, std: 0.00142, params: {'max_depth': 8, 'min_samples_leaf': 5},\n",
       " mean: 0.99791, std: 0.00122, params: {'max_depth': 8, 'min_samples_leaf': 6},\n",
       " mean: 0.99789, std: 0.00132, params: {'max_depth': 8, 'min_samples_leaf': 7},\n",
       " mean: 0.99791, std: 0.00132, params: {'max_depth': 8, 'min_samples_leaf': 8},\n",
       " mean: 0.99794, std: 0.00181, params: {'max_depth': 8, 'min_samples_leaf': 9},\n",
       " mean: 0.99870, std: 0.00158, params: {'max_depth': 8, 'min_samples_leaf': 10},\n",
       " mean: 0.99828, std: 0.00141, params: {'max_depth': 8, 'min_samples_leaf': 11},\n",
       " mean: 0.99875, std: 0.00162, params: {'max_depth': 8, 'min_samples_leaf': 12},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 8, 'min_samples_leaf': 13},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 8, 'min_samples_leaf': 14},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 8, 'min_samples_leaf': 15},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 8, 'min_samples_leaf': 16},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 8, 'min_samples_leaf': 17},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 8, 'min_samples_leaf': 18},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 8, 'min_samples_leaf': 19},\n",
       " mean: 0.99576, std: 0.00277, params: {'max_depth': 10, 'min_samples_leaf': 1},\n",
       " mean: 0.99627, std: 0.00262, params: {'max_depth': 10, 'min_samples_leaf': 2},\n",
       " mean: 0.99596, std: 0.00255, params: {'max_depth': 10, 'min_samples_leaf': 3},\n",
       " mean: 0.99631, std: 0.00262, params: {'max_depth': 10, 'min_samples_leaf': 4},\n",
       " mean: 0.99751, std: 0.00142, params: {'max_depth': 10, 'min_samples_leaf': 5},\n",
       " mean: 0.99791, std: 0.00122, params: {'max_depth': 10, 'min_samples_leaf': 6},\n",
       " mean: 0.99789, std: 0.00132, params: {'max_depth': 10, 'min_samples_leaf': 7},\n",
       " mean: 0.99791, std: 0.00132, params: {'max_depth': 10, 'min_samples_leaf': 8},\n",
       " mean: 0.99794, std: 0.00181, params: {'max_depth': 10, 'min_samples_leaf': 9},\n",
       " mean: 0.99870, std: 0.00158, params: {'max_depth': 10, 'min_samples_leaf': 10},\n",
       " mean: 0.99828, std: 0.00141, params: {'max_depth': 10, 'min_samples_leaf': 11},\n",
       " mean: 0.99875, std: 0.00162, params: {'max_depth': 10, 'min_samples_leaf': 12},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 10, 'min_samples_leaf': 13},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 10, 'min_samples_leaf': 14},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 10, 'min_samples_leaf': 15},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 10, 'min_samples_leaf': 16},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 10, 'min_samples_leaf': 17},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 10, 'min_samples_leaf': 18},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 10, 'min_samples_leaf': 19},\n",
       " mean: 0.99576, std: 0.00277, params: {'max_depth': 20, 'min_samples_leaf': 1},\n",
       " mean: 0.99627, std: 0.00262, params: {'max_depth': 20, 'min_samples_leaf': 2},\n",
       " mean: 0.99596, std: 0.00255, params: {'max_depth': 20, 'min_samples_leaf': 3},\n",
       " mean: 0.99631, std: 0.00262, params: {'max_depth': 20, 'min_samples_leaf': 4},\n",
       " mean: 0.99751, std: 0.00142, params: {'max_depth': 20, 'min_samples_leaf': 5},\n",
       " mean: 0.99791, std: 0.00122, params: {'max_depth': 20, 'min_samples_leaf': 6},\n",
       " mean: 0.99789, std: 0.00132, params: {'max_depth': 20, 'min_samples_leaf': 7},\n",
       " mean: 0.99791, std: 0.00132, params: {'max_depth': 20, 'min_samples_leaf': 8},\n",
       " mean: 0.99794, std: 0.00181, params: {'max_depth': 20, 'min_samples_leaf': 9},\n",
       " mean: 0.99870, std: 0.00158, params: {'max_depth': 20, 'min_samples_leaf': 10},\n",
       " mean: 0.99828, std: 0.00141, params: {'max_depth': 20, 'min_samples_leaf': 11},\n",
       " mean: 0.99875, std: 0.00162, params: {'max_depth': 20, 'min_samples_leaf': 12},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 20, 'min_samples_leaf': 13},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 20, 'min_samples_leaf': 14},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 20, 'min_samples_leaf': 15},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 20, 'min_samples_leaf': 16},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 20, 'min_samples_leaf': 17},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 20, 'min_samples_leaf': 18},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 20, 'min_samples_leaf': 19},\n",
       " mean: 0.99576, std: 0.00277, params: {'max_depth': 50, 'min_samples_leaf': 1},\n",
       " mean: 0.99627, std: 0.00262, params: {'max_depth': 50, 'min_samples_leaf': 2},\n",
       " mean: 0.99596, std: 0.00255, params: {'max_depth': 50, 'min_samples_leaf': 3},\n",
       " mean: 0.99631, std: 0.00262, params: {'max_depth': 50, 'min_samples_leaf': 4},\n",
       " mean: 0.99751, std: 0.00142, params: {'max_depth': 50, 'min_samples_leaf': 5},\n",
       " mean: 0.99791, std: 0.00122, params: {'max_depth': 50, 'min_samples_leaf': 6},\n",
       " mean: 0.99789, std: 0.00132, params: {'max_depth': 50, 'min_samples_leaf': 7},\n",
       " mean: 0.99791, std: 0.00132, params: {'max_depth': 50, 'min_samples_leaf': 8},\n",
       " mean: 0.99794, std: 0.00181, params: {'max_depth': 50, 'min_samples_leaf': 9},\n",
       " mean: 0.99870, std: 0.00158, params: {'max_depth': 50, 'min_samples_leaf': 10},\n",
       " mean: 0.99828, std: 0.00141, params: {'max_depth': 50, 'min_samples_leaf': 11},\n",
       " mean: 0.99875, std: 0.00162, params: {'max_depth': 50, 'min_samples_leaf': 12},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 50, 'min_samples_leaf': 13},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 50, 'min_samples_leaf': 14},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 50, 'min_samples_leaf': 15},\n",
       " mean: 0.99840, std: 0.00150, params: {'max_depth': 50, 'min_samples_leaf': 16},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 50, 'min_samples_leaf': 17},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 50, 'min_samples_leaf': 18},\n",
       " mean: 0.99877, std: 0.00161, params: {'max_depth': 50, 'min_samples_leaf': 19}]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57883570156729724"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = DecisionTreeClassifier(random_state=241, max_depth=10, min_samples_leaf=10)\n",
    "ds.fit(X_new_train, y_train)\n",
    "roc_auc_score(y_test, ds.predict_proba(X_new_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшение незначительно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Настройте случайный лес, подобрав оптимальное число деревьев `n_estimators`. Какое качество на тестовой выборке он дает?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 0.71747272523382211)\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "n_best = 0\n",
    "\n",
    "for n in range(25, 200, 25):\n",
    "    cl = RandomForestClassifier(n_estimators=n)\n",
    "    cl.fit(X_new_train, y_train)\n",
    "    res = roc_auc_score(y_test, cl.predict_proba(X_new_test)[:, 1])\n",
    "    if res > best:\n",
    "        best = res\n",
    "        n_best = n\n",
    "\n",
    "print(n_best, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат при 150 деревьях \n",
    "\n",
    "0.717"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Возьмите выборку с парными признаками, для которой счетчики посчитаны с фолдингом. Обучите на ней случайный лес, подобрав число деревьев. Какое качество на тестовой выборке он дает? Чем вы можете объяснить изменение результата по сравнению с предыдущим пунктом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_super = pd.DataFrame()\n",
    "y_super = np.array((1))\n",
    "pos = 0\n",
    "nf = 4\n",
    "\n",
    "data1 = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "kf = KFold(data.shape[0], n_folds=nf)\n",
    "    \n",
    "for (ind_train, ind_test) in kf:\n",
    "    X_train1 = data1.iloc[ind_train]\n",
    "    X_test1 = data1.iloc[ind_test]\n",
    "    y_train1 = y.iloc[ind_train]\n",
    "    y_test1 = y.iloc[ind_test]\n",
    "    X_new_train, X_new_test = pair_counts(X_train1, X_test1)\n",
    "    X_new_train, X_new_test = add_counts(X_new_train, y_train1, X_new_test, y_test1)\n",
    "    data_super = pd.concat([data_super, X_new_test], axis=0)\n",
    "    y_super = np.hstack((y_super, y_test1))\n",
    "\n",
    "y_super = y_super[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_super, y_super,\n",
    "                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 0.88002939715524398)\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "n_best = 0\n",
    "\n",
    "for n in range(50, 200, 25):\n",
    "    cl = RandomForestClassifier(n_estimators=n)\n",
    "    cl.fit(X_train, y_train)\n",
    "    res = roc_auc_score(y_test, cl.predict_proba(X_test)[:, 1])\n",
    "    if res > best:\n",
    "        best = res\n",
    "        n_best = n\n",
    "\n",
    "print(n_best, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат при 125 деревьяв:\n",
    "    \n",
    "0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сделать вывод, что подсчёт счётчиков с фолдингом не обязателен для KNN, но нужен для лесов, т.к. счётчики без фолдинга быстро приводят к переобучению."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
