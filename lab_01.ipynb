{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 1. Язык Python, основные библиотеки для анализа данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ФИО: Попов Артём Сергеевич"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Группа: 317"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Pyhton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Напишите код, который сформирует список всех натуральных чисел, не превосходящих 100, которые делятся на 7 и не делятся на 5. Нельзя использовать циклы — выполните это задание с помощью list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 14, 21, 28, 42, 49, 56, 63, 77, 84, 91, 98]\n"
     ]
    }
   ],
   "source": [
    "numbers = []\n",
    "numbers = [x for x in range(1, 100) if x % 7 == 0 and x % 5 != 0]\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Напишите функцию sort_tokens(s), которая принимает на вход строку, разделяет ее на токены по запятым, сортирует токены с помощью функции sorted() и снова соединяет их в одну строку через запятые. Например, для строки u\"ночь,фонарь,улица\" функция должна выдать u\"ночь,улица,фонарь\". Придумайте несколько входных строк и протестируйте функцию на них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sort_tokens(s):\n",
    "    words = s.split(',')\n",
    "    words = list(map(lambda s: s.strip(), words)) # удаляем лишние пробельные символы\n",
    "    words.sort()\n",
    "    s = ','.join(words)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Проверка функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ани,асвк,ая,вм,втм,иб,ио,ммп,мс,ндс,ом,оу,са,ски,сп,фап'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_tokens('aaa, bbb, ccc') # идеальный случай\n",
    "sort_tokens('alexey, alexandr, polina, dima, artem, sonya, nadya')\n",
    "sort_tokens('ммп, мс, ая, сп, втм, са, ани, ом, фап, вм, асвк, ски, ндс, оу, иб, ио')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Напишите функцию remove_duplicates(a), которая принимает на вход список и возвращает его же, но без дубликатов и в отсортированном виде. Например, для списка [u\"ночь\", u\"улица\", u\"фонарь\", u\"аптека\", u\"аптека\", u\"улица\", u\"фонарь\"] результат должен быть [u\"аптека\", u\"ночь\", u\"улица\", u\"фонарь\", ]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(words):\n",
    "    set_of_words = set(words)\n",
    "    words = list(set_of_words)\n",
    "    words.sort()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'g', 'j', 'u', 'z']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_duplicates(['u', 'u', 'a', 'c', 'a', 'a', 'b', 'c', 'b', 'z', 'g', 'z', 'j'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Напишите функцию word_counts(texts), которая принимает на вход список строк, и печатает пары (слово, число вхождений). Считайте, что слова в текстах могут быть разделены только пробелами. Например, для входа [u'ночь улица фонарь аптека', u'аптека улица фонарь'] должно быть напечатано аптека 2 улица 2 фонарь 2 ночь 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import functools # для использования reduce\n",
    "import collections # для defaultdict\n",
    "\n",
    "def word_counts(texts):\n",
    "    texts = list(map(lambda s: s.split(' '), texts))\n",
    "    texts = functools.reduce(lambda l1, l2: l1 + l2, texts)\n",
    "    dic = collections.defaultdict(int)\n",
    "    for item in texts:\n",
    "        dic[item] += 1\n",
    "    for item in dic:\n",
    "        print (item, dic[item])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc 2\n",
      "bb 1\n",
      "bbb 1\n",
      "c 5\n",
      "b 5\n",
      "aa 2\n",
      "a 11\n",
      "aaa 2\n"
     ]
    }
   ],
   "source": [
    "word_counts(['a a a b b c c', 'a aa aaa a bb b b cc c', 'a c cc c a b a bbb a aa aaa a a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (бонусное задание) Скачайте английский перевод \"Преступления и наказания\". Найдите 20 самых популярных слов и 20 слов, которые встречаются только один раз. \n",
    "\n",
    "### Приведите текст к нижнему регистру. Разделите текст на слова, считая разделителями все, кроме букв. Обратите внимание на функцию split из модуля re.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "url = \"http://www.gutenberg.org/files/2554/2554.txt\"\n",
    "response = urllib.request.urlopen(url)\n",
    "raw_text = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слова, встречающиеся один раз\n",
      "cottage\n",
      "moaned\n",
      "commented\n",
      "portly\n",
      "costume\n",
      "verbal\n",
      "chinks\n",
      "fixing\n",
      "knave\n",
      "greek\n",
      "buttoned\n",
      "blurt\n",
      "risky\n",
      "arson\n",
      "voluntary\n",
      "superintend\n",
      "today\n",
      "tatters\n",
      "mushrooms\n",
      "moody\n",
      "\n",
      "Самые частые слова\n",
      "the\n",
      "and\n",
      "to\n",
      "he\n",
      "a\n",
      "i\n",
      "you\n",
      "of\n",
      "it\n",
      "that\n",
      "in\n",
      "was\n",
      "his\n",
      "at\n",
      "her\n",
      "but\n",
      "not\n",
      "s\n",
      "with\n",
      "she\n"
     ]
    }
   ],
   "source": [
    "def word_counts_2(texts):\n",
    "    dic = collections.defaultdict(int)\n",
    "    for item in texts:\n",
    "        dic[item] += 1\n",
    "    return dic\n",
    "\n",
    "words = (filter(lambda x: len(x) != 0, re.split('[^a-z]', raw_text.lower())))\n",
    "\n",
    "dic = word_counts_2(words) # делаем словарь - слово - сколько раз оно встречается\n",
    "words = list(dic.items())\n",
    "words = sorted(words, key = lambda word: word[1]) \n",
    "\n",
    "print('Слова, встречающиеся один раз') \n",
    "for i in range(0, 20):\n",
    "    print(words[i][0])\n",
    "    \n",
    "print('\\nСамые частые слова')\n",
    "for i in (range(-1,-21, -1)):\n",
    "    print(words[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: NumPy и SciPy¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Повторите 1000 раз следующий эксперимент: сгенерируйте две матрицы размера 10×10 из стандартного нормального распределения, перемножьте их (как матрицы) и найдите максимальный элемент. Какое среднее значение по экспериментам у максимальных элементов? 95-процентная квантиль?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.39343284502\n",
      "11.8831627765\n"
     ]
    }
   ],
   "source": [
    "mu = 0\n",
    "sigma = 1\n",
    "maxi = np.zeros((1000))\n",
    "for i in range(0, 1000):\n",
    "    matr1 = np.random.normal(mu, sigma, size = (10, 10))\n",
    "    matr2 = np.random.normal(mu, sigma, size = (10, 10))\n",
    "    matr3 = np.dot(matr1, matr2)\n",
    "    maxi[i] = matr3.max()\n",
    "\n",
    "print(np.mean(maxi))\n",
    "print(np.percentile(maxi, 95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Сгенерируйте 1000 чисел из распределения Пуассона с параметром λ=5. Сформируйте массив, в котором в i-м элементе будет записано количество сгенерированных чисел, равных i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5  30  83 139 177 174 153 100  63  47  12   9   4   0   3   1]\n"
     ]
    }
   ],
   "source": [
    "matr1 = np.random.poisson(lam = 5, size = (1000))\n",
    "matr2 = np.bincount(matr1)\n",
    "print(matr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Реализуйте функцию, которая принимает на вход numpy-массив целых чисел a, и генерирует массив, в котором число i встречается a[i] раз. Протестируйте на результате из прошлого задания.¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'repeat_number' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a67d73b8691c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpmas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpmas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatr2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'repeat_number' is not defined"
     ]
    }
   ],
   "source": [
    "def gen_mas(npmas):\n",
    "    return np.repeat(range(0, len(npmas)), npmas)\n",
    "\n",
    "print(repeat_number(matr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Напишите функцию scale(X), которая принимает на вход матрицу и масштабирует каждый ее столбец (вычитает среднее и делит на стандартное отклонение). Убедитесь, что в функции не будет происходить деления на ноль. Протестируйте на каких-нибудь данных.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.27861642,  0.11969327,  1.31215162,  0.0976938 ,  0.30722492,\n",
       "         0.24833488,  1.49540366, -1.86806429, -1.38480497,  2.22468714],\n",
       "       [-0.06648356,  1.3684115 , -1.87615527, -0.85379267,  2.08491167,\n",
       "        -0.43579741,  0.62610455,  1.46009712,  1.21197343, -0.25850031],\n",
       "       [-0.94705093, -1.65994717, -0.25012448, -1.04745982,  1.1663205 ,\n",
       "         1.49450305, -1.4666688 ,  0.19705911,  0.95498685, -0.81424638],\n",
       "       [ 0.22026465, -0.76093038,  0.70849719,  0.51006389, -0.37047928,\n",
       "         1.29137468,  0.58072643, -0.50551198,  0.96502531, -0.38959596],\n",
       "       [-0.96070735, -0.08517042, -1.3904508 , -0.69915814, -1.34325804,\n",
       "         0.90618777,  0.73827809,  0.84239971,  0.22204959, -0.7518544 ],\n",
       "       [-0.76191305, -1.24371653,  0.47460142,  1.27200176, -0.67469349,\n",
       "        -1.26426792, -0.57624339, -0.46004508, -0.33529338, -0.74449508],\n",
       "       [-0.4026931 , -0.61550126,  0.37524777,  0.03821583, -1.3280846 ,\n",
       "        -1.24470544, -0.93425742,  0.81280881, -1.23546473, -0.1420269 ],\n",
       "       [ 0.69812925,  1.1416886 , -0.59863993,  1.97526154,  0.08114687,\n",
       "         0.42363765,  0.87497648,  1.11166781, -0.50745303, -0.48828028],\n",
       "       [ 0.89378325,  0.73288042,  0.00553486, -1.37391835, -0.08048353,\n",
       "        -1.2977461 ,  0.18883759, -0.76664503,  1.24163285,  1.64660968],\n",
       "       [-0.95194558,  1.00259196,  1.23933763,  0.08109216,  0.15739498,\n",
       "        -0.12152117, -1.52715718, -0.82376618, -1.13265192, -0.28229752]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matr1 = np.random.random(size = (10, 10)) * 100 - 50\n",
    "matr1\n",
    "\n",
    "def scale(X):\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    sigma = np.std(X, axis = 0)\n",
    "    sigma[sigma == 0] = 1 # 0 = все элементы равны => обнуление столбцов, где sigma = 0\n",
    "    X = (X - mu) / sigma\n",
    "    return X\n",
    "\n",
    "scale(matr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Сгенерируйте матрицу с элементами из нормального распределения N(10,1). Найдите ее:¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### определитель; след; наименьший и наибольший элементы; спектральную норму; норму Фробениуса; собственные числа; обратную матрицу\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "det =  3334.15421013\n",
      "trace =  98.0006029317\n",
      "min =  7.22171895954\n",
      "max =  12.8916513416\n",
      "spectral =  98.9182355206\n",
      "frobenius =  99.3128192371\n",
      "eigenvalues =  [ 98.88864925+0.j          -1.97967568+2.44611227j  -1.97967568-2.44611227j\n",
      "   2.29580270+0.27704177j   2.29580270-0.27704177j   0.12857898+2.17825331j\n",
      "   0.12857898-2.17825331j   0.19173345+0.j          -0.46308711+0.j\n",
      "  -1.50610467+0.j        ]\n",
      "inverse matrix =  [[ 0.01928933  0.78512868 -0.37556309  0.06396533  0.21166455 -0.01683113\n",
      "  -0.69091251 -0.15349614 -0.34295656  0.42130378]\n",
      " [ 6.651162    4.38163736 -4.57931026 -2.75603284 -1.08339874 -1.57573071\n",
      "  -1.52892498  1.66104411  0.80487512 -2.38671935]\n",
      " [ 0.47325992  0.43651756 -0.40891601 -0.07021229 -0.24124326 -0.24469618\n",
      "  -0.05028785  0.36122604 -0.07726244 -0.22033349]\n",
      " [ 2.88158387  1.90031926 -2.02103684 -1.73486443 -0.18740753 -0.45164867\n",
      "  -0.72877785  0.55028268  0.51638906 -0.87721451]\n",
      " [ 1.05883219  0.88089383 -1.03368387 -0.34657304  0.18229071 -0.12716586\n",
      "  -0.54915888  0.29371172 -0.14084894 -0.30497628]\n",
      " [ 1.0816402   0.33441087 -0.39180797 -0.4954761  -0.37593983 -0.2433014\n",
      "   0.31621778  0.23525646  0.14606038 -0.60597477]\n",
      " [-6.5953312  -3.62694349  4.26551966  3.25243713  1.30219987  0.90891204\n",
      "   0.91114656 -1.61140821 -1.0685144   2.58546732]\n",
      " [-2.98123218 -2.22911017  2.23206105  0.82757944  0.29047794  1.06904578\n",
      "   1.15382441 -0.7739394   0.04748529  0.62874434]\n",
      " [-1.55335381 -1.54480528  1.47652078  0.71148997 -0.02712492  0.46634375\n",
      "   0.56931044 -0.22845018 -0.03949067  0.32144904]\n",
      " [-1.57441061 -1.67925652  1.23884934  0.79039059  0.01512562  0.35619042\n",
      "   0.74799886 -0.4446702   0.09487199  0.62127973]]\n"
     ]
    }
   ],
   "source": [
    "mu = 10\n",
    "sigma = 1\n",
    "\n",
    "matr = np.random.normal(mu, sigma, size = (10, 10))\n",
    "det = np.linalg.det(matr)\n",
    "print('det = ', det)\n",
    "print('trace = ', np.trace(matr))\n",
    "print('min = ', matr.min())\n",
    "print('max = ', matr.max())\n",
    "print('spectral = ', np.linalg.norm(matr, ord = 2))\n",
    "print('frobenius = ', np.linalg.norm(matr, ord = 'fro'))\n",
    "print('eigenvalues = ', np.linalg.eigvals(matr))\n",
    "if det != 0:\n",
    "    print('inverse matrix = ', np.linalg.inv(matr))\n",
    "else:\n",
    "    print('There is no inverse matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3: Pandas¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ответьте на вопросы о данных по авиарейсам в США за январь-апрель 2008 года.\n",
    "\n",
    "Данные: http://stat-computing.org/dataexpo/2009/2008.csv.bz2 (обратите внимание, что распаковывать этот файл не обязательно — функция pandas.read_csv умеет читать из архивов автоматически)\n",
    "\n",
    "Описание: http://stat-computing.org/dataexpo/2009/the-data.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Location = r'/home/arti32lehtonen/Загрузки/2008.csv.bz2'\n",
    "df = pd.read_csv(Location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max distance =  4962\n",
      "min distance =  11\n",
      "mean distance =  726.387029425\n"
     ]
    }
   ],
   "source": [
    "print('max distance = ', df['Distance'].max())\n",
    "min_dist = df['Distance'].min()\n",
    "print('min distance = ', min_dist)\n",
    "print('mean distance = ', df['Distance'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какая из причин отмены рейса (CancellationCode) была самой частой? (расшифровки кодов можно найти в описании данных)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CancellationCode'].value_counts().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent is B - weather\n"
     ]
    }
   ],
   "source": [
    "print('The most frequent is B - weather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Не выглядит ли подозрительным минимальное пройденное расстояние? В какие дни и на каких рейсах оно было? Какое расстояние было пройдено этими же рейсами в другие дни?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>TailNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2547298</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4988</td>\n",
       "      <td>OH</td>\n",
       "      <td>N806CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392215</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5572</td>\n",
       "      <td>OH</td>\n",
       "      <td>N819CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Month  DayofMonth  DayOfWeek  FlightNum UniqueCarrier TailNum\n",
       "2547298      5          15          4       4988            OH  N806CA\n",
       "4392215      8          10          7       5572            OH  N819CA"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Distance'] == min_dist][['Month', 'DayofMonth', 'DayOfWeek', 'FlightNum', 'UniqueCarrier', 'TailNum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834    130\n",
       "96       1\n",
       "11       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ (df['FlightNum'] == 4988) & (df['UniqueCarrier'] == 'OH')]['Distance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544    243\n",
       "11       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ (df['FlightNum'] == 5572) & (df['UniqueCarrier'] == 'OH')]['Distance'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Из какого аэропорта было произведено больше всего вылетов? В каком городе он находится?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airport = ATL\n",
      "City = Atlanta\n"
     ]
    }
   ],
   "source": [
    "df1 = df['Origin'].value_counts().argmax()\n",
    "print('Airport = ATL')\n",
    "print('City = Atlanta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Найдите для каждого аэропорта среднее время полета (AirTime) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AirTime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Origin</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABE</th>\n",
       "      <td>89.057518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABI</th>\n",
       "      <td>36.789977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABQ</th>\n",
       "      <td>91.657166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABY</th>\n",
       "      <td>35.379759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACK</th>\n",
       "      <td>50.692124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACT</th>\n",
       "      <td>29.875977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACV</th>\n",
       "      <td>58.850658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACY</th>\n",
       "      <td>108.848214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADK</th>\n",
       "      <td>151.423913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADQ</th>\n",
       "      <td>41.987934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AEX</th>\n",
       "      <td>68.543556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGS</th>\n",
       "      <td>36.933814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AKN</th>\n",
       "      <td>37.321429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>101.860527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALO</th>\n",
       "      <td>36.373134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMA</th>\n",
       "      <td>56.196001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANC</th>\n",
       "      <td>156.163749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASE</th>\n",
       "      <td>48.307996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATL</th>\n",
       "      <td>93.320419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATW</th>\n",
       "      <td>50.696326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>101.266600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVL</th>\n",
       "      <td>69.899021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVP</th>\n",
       "      <td>94.665204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZO</th>\n",
       "      <td>34.846602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDL</th>\n",
       "      <td>118.701612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BET</th>\n",
       "      <td>57.597815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFL</th>\n",
       "      <td>64.024511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BGM</th>\n",
       "      <td>66.582260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BGR</th>\n",
       "      <td>90.211095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHM</th>\n",
       "      <td>82.290713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPS</th>\n",
       "      <td>29.490040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRQ</th>\n",
       "      <td>103.083807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STL</th>\n",
       "      <td>99.294409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STT</th>\n",
       "      <td>168.681929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STX</th>\n",
       "      <td>168.101176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUN</th>\n",
       "      <td>48.221851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUX</th>\n",
       "      <td>44.918919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWF</th>\n",
       "      <td>132.768826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYR</th>\n",
       "      <td>84.524087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEX</th>\n",
       "      <td>93.124183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLH</th>\n",
       "      <td>59.293080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOL</th>\n",
       "      <td>48.295047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPA</th>\n",
       "      <td>117.917963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRI</th>\n",
       "      <td>47.871046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TUL</th>\n",
       "      <td>80.876802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TUP</th>\n",
       "      <td>42.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TUS</th>\n",
       "      <td>92.801864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVC</th>\n",
       "      <td>49.328770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TWF</th>\n",
       "      <td>41.316563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TXK</th>\n",
       "      <td>43.796312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TYR</th>\n",
       "      <td>30.372715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TYS</th>\n",
       "      <td>81.030894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VLD</th>\n",
       "      <td>45.158351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPS</th>\n",
       "      <td>75.231116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WRG</th>\n",
       "      <td>16.741606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WYS</th>\n",
       "      <td>62.961977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XNA</th>\n",
       "      <td>84.253180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YAK</th>\n",
       "      <td>36.372159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YKM</th>\n",
       "      <td>80.697329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YUM</th>\n",
       "      <td>48.876952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AirTime\n",
       "Origin            \n",
       "ABE      89.057518\n",
       "ABI      36.789977\n",
       "ABQ      91.657166\n",
       "ABY      35.379759\n",
       "ACK      50.692124\n",
       "ACT      29.875977\n",
       "ACV      58.850658\n",
       "ACY     108.848214\n",
       "ADK     151.423913\n",
       "ADQ      41.987934\n",
       "AEX      68.543556\n",
       "AGS      36.933814\n",
       "AKN      37.321429\n",
       "ALB     101.860527\n",
       "ALO      36.373134\n",
       "AMA      56.196001\n",
       "ANC     156.163749\n",
       "ASE      48.307996\n",
       "ATL      93.320419\n",
       "ATW      50.696326\n",
       "AUS     101.266600\n",
       "AVL      69.899021\n",
       "AVP      94.665204\n",
       "AZO      34.846602\n",
       "BDL     118.701612\n",
       "BET      57.597815\n",
       "BFL      64.024511\n",
       "BGM      66.582260\n",
       "BGR      90.211095\n",
       "BHM      82.290713\n",
       "...            ...\n",
       "SPS      29.490040\n",
       "SRQ     103.083807\n",
       "STL      99.294409\n",
       "STT     168.681929\n",
       "STX     168.101176\n",
       "SUN      48.221851\n",
       "SUX      44.918919\n",
       "SWF     132.768826\n",
       "SYR      84.524087\n",
       "TEX      93.124183\n",
       "TLH      59.293080\n",
       "TOL      48.295047\n",
       "TPA     117.917963\n",
       "TRI      47.871046\n",
       "TUL      80.876802\n",
       "TUP      42.900000\n",
       "TUS      92.801864\n",
       "TVC      49.328770\n",
       "TWF      41.316563\n",
       "TXK      43.796312\n",
       "TYR      30.372715\n",
       "TYS      81.030894\n",
       "VLD      45.158351\n",
       "VPS      75.231116\n",
       "WRG      16.741606\n",
       "WYS      62.961977\n",
       "XNA      84.253180\n",
       "YAK      36.372159\n",
       "YKM      80.697329\n",
       "YUM      48.876952\n",
       "\n",
       "[303 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[['Origin', 'AirTime']]\n",
    "groups = df1.groupby(df1['Origin'])\n",
    "mean_air_time = groups.mean()\n",
    "mean_air_time # не вывожу все аэропорты, но найдены все значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJU\n",
      "Airport == Luis Munoz Marin International San Juan USA\n"
     ]
    }
   ],
   "source": [
    "print(mean_air_time['AirTime'].argmax())\n",
    "print('Airport == Luis Munoz Marin International San Juan USA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Найдите аэропорт, у которого наибольшая доля задержанных (DepDelay > 0) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию filter после groupby).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAL\n",
      "Airport == Dallas Love Field\n"
     ]
    }
   ],
   "source": [
    "df1 = df[['Origin', 'DepDelay']]\n",
    "groups = df1.groupby(['Origin']) # группируем по аэропортам\n",
    "df1 = groups.filter(lambda x: len(x) >= 1000) # исключаем группы с числом элементов меньше 1000\n",
    "groups = df1.groupby('Origin') # снова группируем по аэропортам\n",
    "numb_all = groups.count() # число всех рейсов для каждого аэропорта\n",
    "numb_dep_delay = df1[df1['DepDelay'] > 0].groupby('Origin').count() # число задержанных рейсов\n",
    "ratio = numb_dep_delay / numb_all\n",
    "print(ratio['DepDelay'].argmax())\n",
    "print('Airport == Dallas Love Field')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
